# Performance Testing CI/CD Pipeline
# Automated performance testing for the CFI Handbook application

name: Performance Testing

on:
  push:
    branches: [main, master, develop]
  pull_request:
    branches: [main, master, develop]
  schedule:
    # Run performance tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: Type of performance test to run
        required: true
        default: full
        type: choice
        options:
          - full
          - lighthouse
          - load
          - api
      target_url:
        description: Target URL for testing (optional)
        required: false
        default: ''

env:
  NODE_VERSION: '20'
  PERFORMANCE_BUDGET_CPU: '5000' # 5 seconds
  PERFORMANCE_BUDGET_MEMORY: '512' # 512 MB
  LIGHTHOUSE_BUDGET_PERFORMANCE: '90'
  LIGHTHOUSE_BUDGET_ACCESSIBILITY: '95'
  LIGHTHOUSE_BUDGET_BEST_PRACTICES: '90'
  LIGHTHOUSE_BUDGET_SEO: '90'

jobs:
  lighthouse-audit:
    name: Lighthouse Performance Audit
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'full' || github.event.inputs.test_type == 'lighthouse' || github.event.inputs.test_type == ''

    strategy:
      matrix:
        device: [desktop, mobile]
        page: [/, /handbook, /dashboard]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build
        env:
          NEXT_TELEMETRY_DISABLED: 1
          NEXT_PUBLIC_SENTRY_DISABLED: true

      - name: Start application
        run: |
          npm start &
          sleep 30 # Wait for app to start
        env:
          PORT: 3000

      - name: Wait for application to be ready
        run: |
          timeout 60 bash -c 'while ! nc -z localhost 3000; do sleep 1; done'

      - name: Run Lighthouse CI
        uses: treosh/lighthouse-ci-action@v10
        with:
          configPath: ./.lighthouserc.json
          urls: |
            http://localhost:3000${{ matrix.page }}
          uploadArtifacts: true
          temporaryPublicStorage: true
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}

      - name: Upload Lighthouse results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: lighthouse-results-${{ matrix.device }}-${{ github.sha }}
          path: |
            .lighthouseci/
            lighthouse-results.json
          retention-days: 30

  load-testing:
    name: Load Testing
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'full' || github.event.inputs.test_type == 'load' || github.event.inputs.test_type == ''

    strategy:
      matrix:
        scenario: [light, moderate, heavy]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm

      - name: Install dependencies
        run: npm ci

      - name: Install k6
        run: |
          sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Build application
        run: npm run build
        env:
          NEXT_TELEMETRY_DISABLED: 1
          NEXT_PUBLIC_SENTRY_DISABLED: true

      - name: Start application
        run: |
          npm start &
          sleep 30
        env:
          PORT: 3000

      - name: Run load test - ${{ matrix.scenario }}
        run: |
          k6 run --out json=load-test-results-${{ matrix.scenario }}.json \
            scripts/performance/load-test-${{ matrix.scenario }}.js
        env:
          TARGET_URL: http://localhost:3000

      - name: Process load test results
        run: |
          node scripts/performance/process-load-results.js \
            load-test-results-${{ matrix.scenario }}.json \
            ${{ matrix.scenario }}

      - name: Upload load test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: load-test-results-${{ matrix.scenario }}-${{ github.sha }}
          path: |
            load-test-results-*.json
            load-test-summary-*.json
          retention-days: 30

  api-performance-testing:
    name: API Performance Testing
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'full' || github.event.inputs.test_type == 'api' || github.event.inputs.test_type == ''

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build
        env:
          NEXT_TELEMETRY_DISABLED: 1
          NEXT_PUBLIC_SENTRY_DISABLED: true

      - name: Start application
        run: |
          npm start &
          sleep 30
        env:
          PORT: 3000

      - name: Run API performance tests
        run: |
          npm run test:api-performance
        env:
          API_BASE_URL: http://localhost:3000

      - name: Upload API test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: api-performance-results-${{ github.sha }}
          path: |
            api-performance-results.json
            api-performance-report.html
          retention-days: 30

  performance-budget-check:
    name: Performance Budget Check
    runs-on: ubuntu-latest
    needs: [lighthouse-audit, load-testing, api-performance-testing]
    if: always()

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./performance-results

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm

      - name: Install dependencies
        run: npm ci

      - name: Check performance budgets
        run: |
          node scripts/performance/budget-check.js ./performance-results
        env:
          LIGHTHOUSE_BUDGET_PERFORMANCE: ${{ env.LIGHTHOUSE_BUDGET_PERFORMANCE }}
          LIGHTHOUSE_BUDGET_ACCESSIBILITY: ${{ env.LIGHTHOUSE_BUDGET_ACCESSIBILITY }}
          LIGHTHOUSE_BUDGET_BEST_PRACTICES: ${{ env.LIGHTHOUSE_BUDGET_BEST_PRACTICES }}
          LIGHTHOUSE_BUDGET_SEO: ${{ env.LIGHTHOUSE_BUDGET_SEO }}

      - name: Generate performance report
        run: |
          node scripts/performance/generate-report.js ./performance-results

      - name: Upload performance report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-report-${{ github.sha }}
          path: |
            performance-report.html
            performance-summary.json
          retention-days: 90

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = './performance-summary.json';

            if (fs.existsSync(path)) {
              const summary = JSON.parse(fs.readFileSync(path, 'utf8'));

              const comment = `## üéØ Performance Test Results

              ### Lighthouse Scores
              - **Performance**: ${summary.lighthouse.performance}/100
              - **Accessibility**: ${summary.lighthouse.accessibility}/100
              - **Best Practices**: ${summary.lighthouse.bestPractices}/100
              - **SEO**: ${summary.lighthouse.seo}/100

              ### Load Testing
              - **Average Response Time**: ${summary.loadTest.avgResponseTime}ms
              - **95th Percentile**: ${summary.loadTest.p95ResponseTime}ms
              - **Error Rate**: ${summary.loadTest.errorRate}%
              - **Throughput**: ${summary.loadTest.throughput} req/s

              ### API Performance
              - **Average API Response**: ${summary.api.avgResponseTime}ms
              - **Slowest Endpoint**: ${summary.api.slowestEndpoint}
              - **Total Requests**: ${summary.api.totalRequests}

              ### Budget Compliance
              ${summary.budgetPassed ? '‚úÖ All performance budgets passed!' : '‚ùå Some performance budgets failed. See details in the full report.'}

              [View Full Performance Report](${summary.reportUrl})`;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }

  railway-deployment-performance:
    name: Railway Deployment Performance
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Wait for Railway deployment
        run: |
          echo "Waiting for Railway deployment to complete..."
          sleep 120 # Wait 2 minutes for deployment

      - name: Test production performance
        run: |
          # Test production URL if available
          TARGET_URL="${{ github.event.inputs.target_url || secrets.RAILWAY_PRODUCTION_URL }}"
          if [ -n "$TARGET_URL" ]; then
            curl -f "$TARGET_URL/api/health" || exit 1

            # Run basic performance checks
            node scripts/performance/production-check.js "$TARGET_URL"
          else
            echo "No production URL available for testing"
          fi

      - name: Upload production test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: production-performance-${{ github.sha }}
          path: |
            production-performance.json
          retention-days: 30

  notify-performance-results:
    name: Notify Performance Results
    runs-on: ubuntu-latest
    needs: [performance-budget-check, railway-deployment-performance]
    if: always() && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')

    steps:
      - name: Download performance report
        uses: actions/download-artifact@v4
        with:
          name: performance-report-${{ github.sha }}

      - name: Send Slack notification
        if: env.SLACK_WEBHOOK_URL != ''
        run: |
          # Send performance results to Slack (if configured)
          curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"üéØ Performance test results for commit ${{ github.sha }}: Performance scores and load test results available in GitHub Actions artifacts.\"}" \
            ${{ secrets.SLACK_WEBHOOK_URL }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Create performance issue
        if: needs.performance-budget-check.result == 'failure'
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üö® Performance Budget Failure - ${new Date().toISOString().split('T')[0]}`,
              body: `Performance tests failed for commit ${context.sha}.

              One or more performance budgets were exceeded. Please review the performance test results and optimize accordingly.

              **Commit**: ${context.sha}
              **Workflow**: ${context.workflow}
              **Run**: https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}

              ## Next Steps
              1. Review the performance test artifacts
              2. Identify the root cause of performance degradation
              3. Implement optimizations
              4. Re-run performance tests

              This issue will be automatically closed when performance budgets pass again.`,
              labels: ['performance', 'bug', 'high-priority']
            });
